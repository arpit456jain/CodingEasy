{% extends 'home/base.html' %}
{% load static %}

{% block content %}

<style>


@media (min-width: 768px) {
.main {
padding-right: 40px;
padding-left: 220px; /* 180 + 40 */
}
}


.sidebar {
position: fixed;
top: 75px;
bottom: 0;
left: 0;
z-index:1;
width: 290px;
display: block;
padding: 20px;
overflow-x: hidden;
overflow-y: auto; /* Scrollable contents if viewport is shorter than content. */
background-color:blue;
font-color:white;
border-right: 1px solid #eee;
}
</style>



<div class="container-sm">
<div class="row">

<div class="sidebar">


  <div class="col-sm-3 col-md-2 sidebar">



      <h2 ><a href="ML.html" class="btn btn-primary btn-lg btn-block" style="color:white;">Introduction</a></h2><br />
      <h2 ><a href="{% url 'ml1' %}?data=linregx" class="btn btn-primary btn-lg btn-block" style="color:white;">Linear Regression</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=logregx" style="color:white;">Logistic Regression</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=knn" class="btn btn-primary btn-lg btn-block" style="color:white;">k-nearest neighbours</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=svm" class="btn btn-primary btn-lg btn-block" style="color:white;">Support Vector machines</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=decitree" class="btn btn-primary btn-lg btn-block" style="color:white;">Decision Tree</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=rf" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Random Forest</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=nv" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Naive Bayes</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=kmc" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">k Means Clustering</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=hrc" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Hierarchical Clustering</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=ohe" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">One Hot Encoding</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=kcv" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">K-Fold Cross Validation</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=gs" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Grid Search</a></h2><br/>





</div>
</div>
</div>
</div>

<section class="container mt-3">
    <div class="row">
        <div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">
            <div class="jumbotron px-3 py-4 px-sm-4 py-sm-5 bg-light rounded-3 mb-3">
                <h1 class="text-center">K Means Clustering (Clustering Algorithm)</h1>

            </div>
</section>
<br><br>

<section class="container mt-5">
    <div class="row">
        <div class="col-md-6 col-sm-12 main">
            <h3 class="text-center">K Means Clustering</h3>
            <p>K Means Clustering includes formation of clusters of the datapoints and data points with most similarity
                is placed under 1 cluster. Machine groups the data to same cluster without labels and finds common
                patterns to predict the unknown
                data class value. </p>
            <p>The algorithm proceeds in similar way as K Nearest Neighbors which means by choosing a value of k.
                Suppose k=3 so there will be 3 clusters formed as shown without labels.</p>
            <p>Each cluster has a centroid point which marks the cluster. We first start with taking random value of
                centroid point of all clusters. Then we can find distance between two clusters.</p>
            <P>There will be a midpoint of the distance between the two centroids and from there a perpendicular bisetor
                is passing which acts as a boundary between them. Now we try to make the boundary line in an optimized
                way to make the predictions.</P>
            <P>When a new datapoint is placed then we try to assign that to an existing cluster to find the value which
                is assigned to that datapoint.</P>
        </div>
        <div class="col-md-6 col-sm-12">
            <h3 class="text-center">Plot Picture</h3>
            <div class="code">
                <pre>
                        <img src="{% static 'img/KMeansClustering_Plot.jpg' %}",height=500px, width=500px>
            </pre>
            </div>
        </div>
    </div>
</section>
<br><br>


<br><br>
{% endblock content %}
