{% extends 'home/base.html' %}
{% load static %}

{% block content %}

<style>


@media (min-width: 768px) {
.main {
padding-right: 40px;
padding-left: 220px; /* 180 + 40 */
}
}


.sidebar {
position: fixed;
top: 75px;
bottom: 0;
left: 0;
z-index:1;
width: 290px;
display: block;
padding: 20px;
overflow-x: hidden;
overflow-y: auto; /* Scrollable contents if viewport is shorter than content. */
background-color:blue;
font-color:white;
border-right: 1px solid #eee;
}
</style>



<div class="container-sm">
<div class="row">

<div class="sidebar">


  <div class="col-sm-3 col-md-2 sidebar">



      <h2 ><a href="ML.html" class="btn btn-primary btn-lg btn-block" style="color:white;">Introduction</a></h2><br />
      <h2 ><a href="{% url 'ml1' %}?data=linregx" class="btn btn-primary btn-lg btn-block" style="color:white;">Linear Regression</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=logregx" style="color:white;">Logistic Regression</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=knn" class="btn btn-primary btn-lg btn-block" style="color:white;">k-nearest neighbours</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=svm" class="btn btn-primary btn-lg btn-block" style="color:white;">Support Vector machines</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=decitree" class="btn btn-primary btn-lg btn-block" style="color:white;">Decision Tree</a></h2><br />
      <h2><a href="{% url 'ml1' %}?data=rf" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Random Forest</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=nv" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Naive Bayes</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=kmc" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">k Means Clustering</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=hrc" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Hierarchical Clustering</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=ohe" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">One Hot Encoding</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=kcv" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">K-Fold Cross Validation</a></h2><br/>
      <h2><a href="{% url 'ml1' %}?data=gs" class="btn btn-primary btn-lg btn-block" style="color:white;text-align:center;">Grid Search</a></h2><br/>





</div>
</div>
</div>
</div>

<section class="container mt-3">
    <div class="row">
        <div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 main">
            <div class="jumbotron px-3 py-4 px-sm-4 py-sm-5 bg-light rounded-3 mb-3">
                <h1 class="text-center">Logistic Regression (Classification Algorithm)</h1>

            </div>
</section>
<br><br>

<section class="container mt-5">
    <div class="row">
        <div class="col-md-6 col-sm-12 main">
            <h3 class="text-center">Logistic Regression</h3>
            <p>Logistic Regression is a Classification algorithm which is mostly used for Binary Classification problems
                which includes 2 classes/categories</p>
            <p>This algorithm is named after the term "Regression" because it is the only Classification algorithm which
                uses the mathematical concept very similar to Linear Regression</p>
            <p>This algorithm is widely used in classifying problems like if image is cat/dog or any sentence is
                spam/ham etc.</p>
            <p>As shown in the plot the circle markers(Blue Dots) are actual values and the best fit line(Red Line)
                represents the predicted values. Also there are 2 class values represented by 0 & 1. If a straight line
                is taken like Linear Regression
                then most of the points will be missed whereas if an S shaped curve called Sigmoid Curve is taken then
                most points are covered.
            </p>
            <p>After this we try to find the error which is the difference between predicted and actual value. We also
                try to minimize the error and thus adjust the best fit line so that we get minimum error. Once we get
                the perfect best fit line for
                our problem then we are all good to go for predicting unknown values.
            </p>
        </div>
        <div class="col-md-6 col-sm-12">
            <h3 class="text-center">Plot Picture</h3>
            <div class="code">
                <pre>
            <img src="{% static 'img/LogisticRegex_Plot.jpg' %}",height=500px, width=500px>
        </pre>
            </div>
        </div>
    </div>
</section>
<br><br>


<br><br>
{% endblock content %}
